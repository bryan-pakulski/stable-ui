# Main Canvas

- Basic drawing tools (draw, erase, colour)
- Save canvas to file
- Load saved canvas
- Render chunk objects to seperate framebuffer, this is used for the selection window as it will include an alpha channel, final render step is to copy to main framebuffer


# Core systems

- initialise string with a maximum length, this is important as if we reload configuration by editing the string manually via ImGui we don't have the hooks to re-size memory and we risk overwriting if the initial string is too short (This can potentially be resolved by using std::string as a resizable datatype, see imgui_stdlib.h)
- Add input sanitisation on sd_client on messages being sent, delimit or convert " to '?
- Refactor main rendering code


# Functionality

- Add search and indexing system on prompt, image hash etc.. for image browser, will need some sort of metadata saved for each image generated (store inside image??)
- Add support for textual inversion, see: https://towardsdatascience.com/how-to-fine-tune-stable-diffusion-using-textual-inversion-b995d7ecc095
- Delete models & configurations window
- Save output to temporary folder - "gen??" This way you can generate multiple item etc.. and move them automatically after generation is finished to an output folder
- Add fix faces option:
	https://github.com/TencentARC/GFPGAN
	https://huggingface.co/spaces/akhaliq/GFPGAN/blob/main/app.py
- Show existing configuration when editing model config
- Power of two scaling for selection box
- Adjustable grid snapping
- Render grid
- Load module progress bar or status window

# Bugs

- Max of 27 images generated before overwriting, decide on new naming format
- Save canvas buffer coordinates not working correctly
- Selection not offseting correctly on Y axis, constrained to initial screenspace (check transform logic)
- Crash when docker closes and then ui is closed afterwards
- Extra configuration i.e. trigger_prompt not being loaded from model yaml